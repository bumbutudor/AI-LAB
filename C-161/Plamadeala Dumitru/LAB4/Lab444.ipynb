{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arborele de decizie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importăm librăriile necesare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Încărcarea librăriilor\n",
    "import pandas as pd # Dataframe-ul și series-ul nostru\n",
    "from sklearn.tree import DecisionTreeClassifier # Importăm Clasificatorul „Arborele decizional”\n",
    "from sklearn.model_selection import train_test_split # Importăm funcția de separare a datelor în date de antrenare și date de testare\n",
    "from sklearn import metrics #Importăm modulel metrici pentru caluclarea acurateții"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importăm setul de date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eu voi lucra cu data set-ul Breast Cancer\n",
    "Labels:\n",
    "1=Healthy controls\n",
    "2=Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                71.000000\n",
       "BMI                30.300000\n",
       "Glucose           102.000000\n",
       "Insulin             8.340000\n",
       "HOMA                2.098344\n",
       "Leptin             56.502000\n",
       "Adiponectin         8.130000\n",
       "Resistin            4.298900\n",
       "MCP.1             200.976000\n",
       "Classification      1.000000\n",
       "Name: 44, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# încărcarea setului de date\n",
    "BC = pd.read_csv(\"data/dataR2.csv\")\n",
    "BC.iloc[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#despărțim datasetul în vector de caracteristici (features) și vectorul clasă\n",
    "features = [ 'Age','BMI','Glucose','Insulin','HOMA','Leptin','Adiponectin','Resistin','MCP.1']\n",
    "X = BC[features] # caracteristicile (atributele pentru X)\n",
    "y = BC.Classification # Variabila clasă (independentă dacă facem analogie cu regresia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Împărțirea setului de date\n",
    "Pentru a evalua performanța modelului o strategie ar fie împărțirea setului de date în: date de antrenare/învățare și date pentru testare/evaluare.\n",
    "\n",
    "Putem face acest lucru utilizând funcția train_test_split(). Funcția ia 3 parametri: caracteristicile, clasa și lungimea setului de date pentru testare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>HOMA</th>\n",
       "      <th>Leptin</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>Resistin</th>\n",
       "      <th>MCP.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>49</td>\n",
       "      <td>29.777778</td>\n",
       "      <td>70</td>\n",
       "      <td>8.396</td>\n",
       "      <td>1.449709</td>\n",
       "      <td>51.3387</td>\n",
       "      <td>10.731740</td>\n",
       "      <td>20.76801</td>\n",
       "      <td>602.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>71</td>\n",
       "      <td>30.300000</td>\n",
       "      <td>102</td>\n",
       "      <td>8.340</td>\n",
       "      <td>2.098344</td>\n",
       "      <td>56.5020</td>\n",
       "      <td>8.130000</td>\n",
       "      <td>4.29890</td>\n",
       "      <td>200.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>42</td>\n",
       "      <td>21.359915</td>\n",
       "      <td>93</td>\n",
       "      <td>2.999</td>\n",
       "      <td>0.687971</td>\n",
       "      <td>19.0826</td>\n",
       "      <td>8.462915</td>\n",
       "      <td>17.37615</td>\n",
       "      <td>321.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>40</td>\n",
       "      <td>27.636054</td>\n",
       "      <td>103</td>\n",
       "      <td>2.432</td>\n",
       "      <td>0.617890</td>\n",
       "      <td>14.3224</td>\n",
       "      <td>6.783870</td>\n",
       "      <td>26.01360</td>\n",
       "      <td>293.123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>44</td>\n",
       "      <td>19.560000</td>\n",
       "      <td>114</td>\n",
       "      <td>15.890</td>\n",
       "      <td>4.468268</td>\n",
       "      <td>13.0800</td>\n",
       "      <td>20.370000</td>\n",
       "      <td>4.62000</td>\n",
       "      <td>220.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>72</td>\n",
       "      <td>25.590000</td>\n",
       "      <td>82</td>\n",
       "      <td>2.820</td>\n",
       "      <td>0.570392</td>\n",
       "      <td>24.9600</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>3.27000</td>\n",
       "      <td>392.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>72</td>\n",
       "      <td>23.620000</td>\n",
       "      <td>105</td>\n",
       "      <td>4.420</td>\n",
       "      <td>1.144780</td>\n",
       "      <td>21.7800</td>\n",
       "      <td>17.860000</td>\n",
       "      <td>4.82000</td>\n",
       "      <td>195.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>51</td>\n",
       "      <td>19.132653</td>\n",
       "      <td>93</td>\n",
       "      <td>4.364</td>\n",
       "      <td>1.001102</td>\n",
       "      <td>11.0816</td>\n",
       "      <td>5.807620</td>\n",
       "      <td>5.57055</td>\n",
       "      <td>90.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>67</td>\n",
       "      <td>29.606767</td>\n",
       "      <td>79</td>\n",
       "      <td>5.819</td>\n",
       "      <td>1.133929</td>\n",
       "      <td>21.9033</td>\n",
       "      <td>2.194280</td>\n",
       "      <td>4.20750</td>\n",
       "      <td>585.307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>60</td>\n",
       "      <td>26.349292</td>\n",
       "      <td>103</td>\n",
       "      <td>5.138</td>\n",
       "      <td>1.305395</td>\n",
       "      <td>24.2998</td>\n",
       "      <td>2.194280</td>\n",
       "      <td>20.25350</td>\n",
       "      <td>378.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>23.140496</td>\n",
       "      <td>116</td>\n",
       "      <td>4.902</td>\n",
       "      <td>1.402626</td>\n",
       "      <td>17.9973</td>\n",
       "      <td>4.294705</td>\n",
       "      <td>5.26330</td>\n",
       "      <td>518.586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>44</td>\n",
       "      <td>27.887617</td>\n",
       "      <td>99</td>\n",
       "      <td>9.208</td>\n",
       "      <td>2.248594</td>\n",
       "      <td>12.6757</td>\n",
       "      <td>5.478170</td>\n",
       "      <td>23.03306</td>\n",
       "      <td>407.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>23.124670</td>\n",
       "      <td>91</td>\n",
       "      <td>4.498</td>\n",
       "      <td>1.009651</td>\n",
       "      <td>17.9393</td>\n",
       "      <td>22.432040</td>\n",
       "      <td>9.27715</td>\n",
       "      <td>554.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>86</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>201</td>\n",
       "      <td>41.611</td>\n",
       "      <td>20.630734</td>\n",
       "      <td>47.6470</td>\n",
       "      <td>5.357135</td>\n",
       "      <td>24.37010</td>\n",
       "      <td>1698.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>75</td>\n",
       "      <td>30.480000</td>\n",
       "      <td>152</td>\n",
       "      <td>7.010</td>\n",
       "      <td>2.628283</td>\n",
       "      <td>50.5300</td>\n",
       "      <td>10.060000</td>\n",
       "      <td>11.73000</td>\n",
       "      <td>99.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>20.829995</td>\n",
       "      <td>74</td>\n",
       "      <td>4.560</td>\n",
       "      <td>0.832352</td>\n",
       "      <td>7.7529</td>\n",
       "      <td>8.237405</td>\n",
       "      <td>28.03230</td>\n",
       "      <td>382.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>65</td>\n",
       "      <td>30.915577</td>\n",
       "      <td>97</td>\n",
       "      <td>10.491</td>\n",
       "      <td>2.510147</td>\n",
       "      <td>44.0217</td>\n",
       "      <td>3.710090</td>\n",
       "      <td>20.46850</td>\n",
       "      <td>396.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>69</td>\n",
       "      <td>28.444444</td>\n",
       "      <td>108</td>\n",
       "      <td>8.808</td>\n",
       "      <td>2.346451</td>\n",
       "      <td>14.7485</td>\n",
       "      <td>5.288025</td>\n",
       "      <td>16.48508</td>\n",
       "      <td>353.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>60</td>\n",
       "      <td>31.231410</td>\n",
       "      <td>131</td>\n",
       "      <td>30.130</td>\n",
       "      <td>9.736007</td>\n",
       "      <td>37.8430</td>\n",
       "      <td>8.404430</td>\n",
       "      <td>11.50005</td>\n",
       "      <td>396.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>75</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>85</td>\n",
       "      <td>5.197</td>\n",
       "      <td>1.089638</td>\n",
       "      <td>10.3900</td>\n",
       "      <td>9.000805</td>\n",
       "      <td>7.57670</td>\n",
       "      <td>335.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>57</td>\n",
       "      <td>34.838148</td>\n",
       "      <td>95</td>\n",
       "      <td>12.548</td>\n",
       "      <td>2.940415</td>\n",
       "      <td>33.1612</td>\n",
       "      <td>2.364950</td>\n",
       "      <td>9.95420</td>\n",
       "      <td>655.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>61</td>\n",
       "      <td>32.038959</td>\n",
       "      <td>85</td>\n",
       "      <td>18.077</td>\n",
       "      <td>3.790144</td>\n",
       "      <td>30.7729</td>\n",
       "      <td>7.780255</td>\n",
       "      <td>13.68392</td>\n",
       "      <td>444.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>59</td>\n",
       "      <td>28.672626</td>\n",
       "      <td>77</td>\n",
       "      <td>3.188</td>\n",
       "      <td>0.605507</td>\n",
       "      <td>17.0220</td>\n",
       "      <td>16.440480</td>\n",
       "      <td>31.69040</td>\n",
       "      <td>910.489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>20.956608</td>\n",
       "      <td>94</td>\n",
       "      <td>12.305</td>\n",
       "      <td>2.853119</td>\n",
       "      <td>11.2406</td>\n",
       "      <td>8.412175</td>\n",
       "      <td>23.11770</td>\n",
       "      <td>573.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>49</td>\n",
       "      <td>32.461911</td>\n",
       "      <td>134</td>\n",
       "      <td>24.887</td>\n",
       "      <td>8.225983</td>\n",
       "      <td>42.3914</td>\n",
       "      <td>10.793940</td>\n",
       "      <td>5.76800</td>\n",
       "      <td>656.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>34.422174</td>\n",
       "      <td>89</td>\n",
       "      <td>23.194</td>\n",
       "      <td>5.091856</td>\n",
       "      <td>31.2128</td>\n",
       "      <td>8.300955</td>\n",
       "      <td>6.71026</td>\n",
       "      <td>960.246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>64</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>98</td>\n",
       "      <td>5.700</td>\n",
       "      <td>1.377880</td>\n",
       "      <td>12.1905</td>\n",
       "      <td>4.783985</td>\n",
       "      <td>13.91245</td>\n",
       "      <td>395.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>69</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>89</td>\n",
       "      <td>10.704</td>\n",
       "      <td>2.349885</td>\n",
       "      <td>45.2720</td>\n",
       "      <td>8.286300</td>\n",
       "      <td>4.53000</td>\n",
       "      <td>215.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>75</td>\n",
       "      <td>25.700000</td>\n",
       "      <td>94</td>\n",
       "      <td>8.079</td>\n",
       "      <td>1.873251</td>\n",
       "      <td>65.9260</td>\n",
       "      <td>3.741220</td>\n",
       "      <td>4.49685</td>\n",
       "      <td>206.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>52</td>\n",
       "      <td>30.801249</td>\n",
       "      <td>87</td>\n",
       "      <td>30.212</td>\n",
       "      <td>6.483495</td>\n",
       "      <td>29.2739</td>\n",
       "      <td>6.268540</td>\n",
       "      <td>24.24591</td>\n",
       "      <td>764.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>53</td>\n",
       "      <td>36.790166</td>\n",
       "      <td>101</td>\n",
       "      <td>10.175</td>\n",
       "      <td>2.534932</td>\n",
       "      <td>27.1841</td>\n",
       "      <td>20.030000</td>\n",
       "      <td>10.26309</td>\n",
       "      <td>695.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>34</td>\n",
       "      <td>24.242424</td>\n",
       "      <td>92</td>\n",
       "      <td>21.699</td>\n",
       "      <td>4.924226</td>\n",
       "      <td>16.7353</td>\n",
       "      <td>21.823745</td>\n",
       "      <td>12.06534</td>\n",
       "      <td>481.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>62</td>\n",
       "      <td>22.656250</td>\n",
       "      <td>92</td>\n",
       "      <td>3.482</td>\n",
       "      <td>0.790182</td>\n",
       "      <td>9.8648</td>\n",
       "      <td>11.236235</td>\n",
       "      <td>10.69548</td>\n",
       "      <td>703.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>21.470000</td>\n",
       "      <td>78</td>\n",
       "      <td>3.469</td>\n",
       "      <td>0.667436</td>\n",
       "      <td>14.5700</td>\n",
       "      <td>13.110000</td>\n",
       "      <td>6.92000</td>\n",
       "      <td>354.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>35.855815</td>\n",
       "      <td>87</td>\n",
       "      <td>8.576</td>\n",
       "      <td>1.840410</td>\n",
       "      <td>68.5102</td>\n",
       "      <td>4.794200</td>\n",
       "      <td>21.44366</td>\n",
       "      <td>358.624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age        BMI  Glucose  Insulin       HOMA   Leptin  Adiponectin  \\\n",
       "95    49  29.777778       70    8.396   1.449709  51.3387    10.731740   \n",
       "44    71  30.300000      102    8.340   2.098344  56.5020     8.130000   \n",
       "56    42  21.359915       93    2.999   0.687971  19.0826     8.462915   \n",
       "97    40  27.636054      103    2.432   0.617890  14.3224     6.783870   \n",
       "69    44  19.560000      114   15.890   4.468268  13.0800    20.370000   \n",
       "114   72  25.590000       82    2.820   0.570392  24.9600    33.750000   \n",
       "73    72  23.620000      105    4.420   1.144780  21.7800    17.860000   \n",
       "58    51  19.132653       93    4.364   1.001102  11.0816     5.807620   \n",
       "35    67  29.606767       79    5.819   1.133929  21.9033     2.194280   \n",
       "38    60  26.349292      103    5.138   1.305395  24.2998     2.194280   \n",
       "65    45  23.140496      116    4.902   1.402626  17.9973     4.294705   \n",
       "96    44  27.887617       99    9.208   2.248594  12.6757     5.478170   \n",
       "2     82  23.124670       91    4.498   1.009651  17.9393    22.432040   \n",
       "78    86  26.666667      201   41.611  20.630734  47.6470     5.357135   \n",
       "109   75  30.480000      152    7.010   2.628283  50.5300    10.060000   \n",
       "53    45  20.829995       74    4.560   0.832352   7.7529     8.237405   \n",
       "102   65  30.915577       97   10.491   2.510147  44.0217     3.710090   \n",
       "99    69  28.444444      108    8.808   2.346451  14.7485     5.288025   \n",
       "94    60  31.231410      131   30.130   9.736007  37.8430     8.404430   \n",
       "42    75  27.300000       85    5.197   1.089638  10.3900     9.000805   \n",
       "104   57  34.838148       95   12.548   2.940415  33.1612     2.364950   \n",
       "17    61  32.038959       85   18.077   3.790144  30.7729     7.780255   \n",
       "80    59  28.672626       77    3.188   0.605507  17.0220    16.440480   \n",
       "54    49  20.956608       94   12.305   2.853119  11.2406     8.412175   \n",
       "93    49  32.461911      134   24.887   8.225983  42.3914    10.793940   \n",
       "33    43  34.422174       89   23.194   5.091856  31.2128     8.300955   \n",
       "67    64  22.222222       98    5.700   1.377880  12.1905     4.783985   \n",
       "48    69  29.400000       89   10.704   2.349885  45.2720     8.286300   \n",
       "46    75  25.700000       94    8.079   1.873251  65.9260     3.741220   \n",
       "92    52  30.801249       87   30.212   6.483495  29.2739     6.268540   \n",
       "31    53  36.790166      101   10.175   2.534932  27.1841    20.030000   \n",
       "55    34  24.242424       92   21.699   4.924226  16.7353    21.823745   \n",
       "59    62  22.656250       92    3.482   0.790182   9.8648    11.236235   \n",
       "10    34  21.470000       78    3.469   0.667436  14.5700    13.110000   \n",
       "32    28  35.855815       87    8.576   1.840410  68.5102     4.794200   \n",
       "\n",
       "     Resistin     MCP.1  \n",
       "95   20.76801   602.486  \n",
       "44    4.29890   200.976  \n",
       "56   17.37615   321.919  \n",
       "97   26.01360   293.123  \n",
       "69    4.62000   220.660  \n",
       "114   3.27000   392.460  \n",
       "73    4.82000   195.940  \n",
       "58    5.57055    90.600  \n",
       "35    4.20750   585.307  \n",
       "38   20.25350   378.996  \n",
       "65    5.26330   518.586  \n",
       "96   23.03306   407.206  \n",
       "2     9.27715   554.697  \n",
       "78   24.37010  1698.440  \n",
       "109  11.73000    99.450  \n",
       "53   28.03230   382.955  \n",
       "102  20.46850   396.648  \n",
       "99   16.48508   353.568  \n",
       "94   11.50005   396.021  \n",
       "42    7.57670   335.393  \n",
       "104   9.95420   655.834  \n",
       "17   13.68392   444.395  \n",
       "80   31.69040   910.489  \n",
       "54   23.11770   573.630  \n",
       "93    5.76800   656.393  \n",
       "33    6.71026   960.246  \n",
       "67   13.91245   395.976  \n",
       "48    4.53000   215.769  \n",
       "46    4.49685   206.802  \n",
       "92   24.24591   764.667  \n",
       "31   10.26309   695.754  \n",
       "55   12.06534   481.949  \n",
       "59   10.69548   703.973  \n",
       "10    6.92000   354.600  \n",
       "32   21.44366   358.624  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Împărțim setul de date în train set și test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% pentru antrenare and 30% testare\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construirea modelului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crearea obiectului de clasificare pe bază de arbore de decizie cu parametru criterie\n",
    "clasificator = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "\n",
    "# Antrenarea clasificatorului cu datele noastre utilizând metoda fit() și ca parametru avem datele de antrenare\n",
    "clasificator_arbore_decizie = clasificator.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluarea modelului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7714285714285715\n",
      "95     2\n",
      "44     1\n",
      "56     2\n",
      "97     2\n",
      "69     2\n",
      "114    2\n",
      "73     2\n",
      "58     2\n",
      "35     1\n",
      "38     1\n",
      "65     2\n",
      "96     2\n",
      "2      1\n",
      "78     2\n",
      "109    2\n",
      "53     2\n",
      "102    2\n",
      "99     2\n",
      "94     2\n",
      "42     1\n",
      "104    2\n",
      "17     1\n",
      "80     2\n",
      "54     2\n",
      "93     2\n",
      "33     1\n",
      "67     2\n",
      "48     1\n",
      "46     1\n",
      "92     2\n",
      "31     1\n",
      "55     2\n",
      "59     2\n",
      "10     1\n",
      "32     1\n",
      "Name: Classification, dtype: int64 [2 2 2 2 2 1 2 2 1 2 2 2 1 2 2 2 2 2 2 1 2 1 2 2 2 2 2 1 1 1 2 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Prezice clasele pentru setul de testare utilizând metoda predict(parametru_setu_de_testare)\n",
    "y_prezis = clasificator_arbore_decizie.predict(X_test)\n",
    "\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_prezis))\n",
    "print(y_test, y_prezis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "obiect_nou = [[45,29.38475666,90,4.713,1.046286,23.8479,6.644245,15.55625,621.273]]\n",
    "\n",
    "raspuns=clasificator_arbore_decizie.predict(obiect_nou)\n",
    "\n",
    "print(raspuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualizarea arborelui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puteți folosi funcția export_graphviz din Scikit-learn pentru a afișa arborele în Jupyter Notebook. Pentru a face diagram de asemenea este nevoie de biblioteca pudotplus.\n",
    "Pentru instalarea clasică:\n",
    "\n",
    "- pip install graphviz\n",
    "\n",
    "- pip install pydotplus\n",
    "\n",
    "funcția export_graphviz transformă clasificatorul nostru intr-un fișier cu puncte, iar pydotplus convertește aceste puncte într-un fișier png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dp\\envs\\machinelearning\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(clasificator_arbore_decizie, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True, feature_names = features,class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c1df21214697>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'weather.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dp\\envs\\machinelearning\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(path, f, prog)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                 \u001b[1;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1810\u001b[1;33m                 \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m             )\n\u001b[0;32m   1812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dp\\envs\\machinelearning\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, path, prog, format)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m                 \u001b[0mfobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1919\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dp\\envs\\machinelearning\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1958\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[1;32m-> 1960\u001b[1;33m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1962\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "graph.write_png('weather.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concluzii :\n",
    "Pentru lucrarea de laborator numarul 4 am ales un dataset despre cancerul mamar, pe baza a mai multor criterii. Aceasta problema am realizat-o cu ajutorul arborilor de decizii.\n",
    "\n",
    "Pentru a evalua performanța modelului am împărțit setul de date în: date de antrenare/învățare 70% și date pentru testare/evaluare 30%.\n",
    "\n",
    "Putem spune ca arborele obtinut in final ne permite prezicerea cancerului mamar cu   Accuracuratete de : 0.7714285714285715 ceea ce este un procentaj destul de bun.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
